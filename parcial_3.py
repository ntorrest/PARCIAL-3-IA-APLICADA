# -*- coding: utf-8 -*-
"""Parcial 3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1KwlVqkK8LvYdUNY5nj-fgBFLEI0x57o7
"""

!pip install -q sentence-transformers faiss-cpu pypdf

# ============================================
# 1. IMPORTS
# ============================================

from pathlib import Path
import numpy as np
import faiss
from sentence_transformers import SentenceTransformer
from pypdf import PdfReader


# ============================================
# 2. CONFIGURACI칍N
# ============================================
# Ruta del PDF subido
PDF_PATH = "/content/1.-Basta-ya-2021-baja.pdf"   # <-- usa tu ruta exacta

# Modelo encoder: BGE-M3 (multiling칲e, ideal para RAG)
EMBEDDING_MODEL_NAME = "BAAI/bge-m3"

# Par치metros del chunking
CHUNK_SIZE = 1200       # tama침o por chunk en caracteres
CHUNK_OVERLAP = 200     # solapamiento entre chunks


# ============================================
# 3. Lectura y chunking del PDF + METADATA
# ============================================

def load_pdf_text(pdf_path: str):
    """Devuelve lista de (num_pagina, texto)."""
    reader = PdfReader(pdf_path)
    pages = []
    for i, page in enumerate(reader.pages):
        try:
            text = page.extract_text() or ""
        except Exception:
            text = ""
        pages.append((i + 1, text.strip()))
    return pages


def chunk_page_text(page_num, text, pdf_name):
    """Crea chunks con metadata completa."""
    chunks = []
    start = 0
    chunk_idx = 0

    while start < len(text):
        end = start + CHUNK_SIZE
        chunk_text = text[start:end].strip()
        if not chunk_text:
            break

        # Metadata
        obj = {
            "pdf_name": pdf_name,
            "page": page_num,
            "chunk_id": f"{pdf_name}_p{page_num}_c{chunk_idx}",
            "text": chunk_text,
            "char_start": start,
            "char_end": min(end, len(text)),
            "position": chunk_idx
        }

        chunks.append(obj)
        chunk_idx += 1

        # Solapamiento
        start = end - CHUNK_OVERLAP

    return chunks


def build_corpus_from_pdf(pdf_path: str):
    """Devuelve lista de todos los chunks del PDF."""
    pdf_name = Path(pdf_path).name
    pages = load_pdf_text(pdf_path)

    corpus = []
    for page, text in pages:
        if text:
            corpus.extend(chunk_page_text(page, text, pdf_name))

    return corpus


# ============================================
# 4. SEARCHER con BGE-M3 + FAISS
# ============================================

class PDFSemanticSearcher:
    def __init__(self, pdf_path: str):

        print("Cargando modelo BGE-M3...")
        self.model = SentenceTransformer(EMBEDDING_MODEL_NAME)

        print("Construyendo corpus de chunks...")
        self.corpus = build_corpus_from_pdf(pdf_path)
        texts = [c["text"] for c in self.corpus]
        print(f"Total chunks: {len(texts)}")

        print("Generando embeddings con BGE-M3...")
        self.embeddings = self.model.encode(
            texts,
            show_progress_bar=True,
            normalize_embeddings=True   # recomendado para BGE
        )
        self.embeddings = np.array(self.embeddings).astype("float32")

        dim = self.embeddings.shape[1]
        print(f"Creando 칤ndice FAISS (dim={dim})...")
        self.index = faiss.IndexFlatL2(dim)
        self.index.add(self.embeddings)

        print("칈ndice listo 九덢잺\n")

    def search(self, query: str, top_k: int = 5):
        """Devuelve los top-K chunks m치s similares a la pregunta."""

        # Embedding de la pregunta
        query_vec = self.model.encode(
            [query],
            normalize_embeddings=True
        ).astype("float32")

        distances, indices = self.index.search(query_vec, top_k)
        distances, indices = distances[0], indices[0]

        results = []
        for dist, idx in zip(distances, indices):
            c = self.corpus[int(idx)]
            results.append({
                "score": float(dist),
                "pdf": c["pdf_name"],
                "page": c["page"],
                "chunk_id": c["chunk_id"],
                "char_range": (c["char_start"], c["char_end"]),
                "position": c["position"],
                "text": c["text"]
            })

        return results


# ============================================
# 5. BUCLE INTERACTIVO DE PREGUNTAS
# ============================================

if __name__ == "__main__":
    searcher = PDFSemanticSearcher(PDF_PATH)

    print("Buscador cargado. Pregunta lo que quieras del PDF.\n")

    while True:
        query = input("Pregunta: ").strip()
        if query.lower() in ["salir", "exit", "quit"]:
            print("Chao 游녦")
            break

        results = searcher.search(query, top_k=5)

        print("\n========= TOP K RESULTADOS =========\n")
        for i, r in enumerate(results, 1):
            print(f"[{i}] Score: {r['score']:.4f}")
            print(f"PDF: {r['pdf']}")
            print(f"P치gina: {r['page']} | Chunk: {r['chunk_id']}")
            print(f"Rango caracteres: {r['char_range']}")
            print(f"Posici칩n en p치gina: {r['position']}")
            print("-" * 60)

            preview = r["text"]
            if len(preview) > 700:
                preview = preview[:700] + "..."
            print(preview)
            print("\n" + "="*80 + "\n")

# ============================================
# 5. BUCLE INTERACTIVO DE PREGUNTAS
# ============================================

if __name__ == "__main__":
    searcher = PDFSemanticSearcher(PDF_PATH)

    print("Buscador cargado. Pregunta lo que quieras del PDF.\n")

    while True:
        query = input("Pregunta: ").strip()
        if query.lower() in ["salir", "exit", "quit"]:
            print("Chao 游녦")
            break

        results = searcher.search(query, top_k=5)

        print("\n========= TOP K RESULTADOS =========\n")
        for i, r in enumerate(results, 1):
            print(f"[{i}] Score: {r['score']:.4f}")
            print(f"PDF: {r['pdf']}")
            print(f"P치gina: {r['page']} | Chunk: {r['chunk_id']}")
            print(f"Rango caracteres: {r['char_range']}")
            print(f"Posici칩n en p치gina: {r['position']}")
            print("-" * 60)

            preview = r["text"]
            if len(preview) > 700:
                preview = preview[:700] + "..."
            print(preview)
            print("\n" + "="*80 + "\n")

from pypdf import PdfReader
from pypdf.errors import PdfReadError

def check_pdf_integrity(pdf_path):
    try:
        reader = PdfReader(pdf_path)
        # Attempt to access a property to force parsing, like number of pages
        num_pages = len(reader.pages)
        print(f"PDF integrity check passed: Successfully read {num_pages} pages from '{pdf_path}'.")
        return True
    except PdfReadError as e:
        print(f"PDF integrity check failed for '{pdf_path}': {e}")
        print("This often indicates a corrupted, malformed, or encrypted PDF. Please ensure the file is valid and not password-protected.")
        return False
    except Exception as e:
        print(f"An unexpected error occurred while checking '{pdf_path}': {e}")
        return False

# Run the integrity check
check_pdf_integrity(PDF_PATH)

